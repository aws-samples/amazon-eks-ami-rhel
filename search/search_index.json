{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Amazon EKS AMI RHEL Build Specification","text":"<p>This repository contains resources and configuration scripts for building a custom Amazon EKS AMI running on Red Hat Enterprise Linux with HashiCorp Packer. This is a forked version of the configuration that Amazon EKS uses to create the official Amazon EKS-optimized AMI.</p> <p>Check out the \ud83d\udcd6 documentation to learn more.</p>"},{"location":"#announcements","title":"\ud83d\udd14 Announcements","text":""},{"location":"#this-code-base-now-follows-the-amazon-linux-2023-custom-eks-ami-code-base","title":"This code base now follows the Amazon Linux 2023 custom EKS AMI code base","text":"<p>This code base has always followed the awslabs amazon-eks-ami code base as closely as possible. * Significant changes were made to that upstream code base to provide EKS support for Amazon Linux 2023. * Because Amazon Linux 2 is now under extended support, this code base will now follow the Amazon Linux 2023 code base of the upstream repository. * The scripts for creating worker node groups have been modified to account for how worker nodes join EKS clusters under the new process. * The previous code base, which was based on Amazon Linux 2 build scripts, will remain available under the al2-base branch.</p>"},{"location":"#getting-started","title":"\ud83d\ude80 Getting started","text":"<p>If you are new to Amazon EKS, we recommend that you follow our Getting Started chapter in the Amazon EKS User Guide. If you already have a cluster, and you want to launch a node group with your new AMI, see Launching Amazon EKS Worker Nodes.</p>"},{"location":"#pre-requisites","title":"\ud83d\udd22 Pre-requisites","text":"<ul> <li>RHEL image of your choosing.</li> <li>Internet connectivity from EC2 for file downloads OR files stored locally in S3 bucket.</li> <li>You must have Packer version 1.8.0 or later installed on your local system, an EC2 Instance in AWS, or in AWS CloudShell. For more information, see Installing Packer in the Packer documentation.</li> <li>You must also have AWS account credentials configured so that Packer can make calls to AWS API operations on your behalf. For more information, see Authentication in the Packer documentation.</li> <li>We recommend using AWS CloudShell for simplicity.</li> </ul>"},{"location":"#minimal-packer-iam-permissions","title":"\ud83e\udeaa Minimal Packer IAM Permissions","text":"<pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"ec2:AttachVolume\",\n        \"ec2:AuthorizeSecurityGroupIngress\",\n        \"ec2:CopyImage\",\n        \"ec2:CreateImage\",\n        \"ec2:CreateKeypair\",\n        \"ec2:CreateSecurityGroup\",\n        \"ec2:CreateSnapshot\",\n        \"ec2:CreateTags\",\n        \"ec2:CreateVolume\",\n        \"ec2:DeleteKeyPair\",\n        \"ec2:DeleteSecurityGroup\",\n        \"ec2:DeleteSnapshot\",\n        \"ec2:DeleteVolume\",\n        \"ec2:DeregisterImage\",\n        \"ec2:DescribeImageAttribute\",\n        \"ec2:DescribeImages\",\n        \"ec2:DescribeInstances\",\n        \"ec2:DescribeInstanceStatus\",\n        \"ec2:DescribeRegions\",\n        \"ec2:DescribeSecurityGroups\",\n        \"ec2:DescribeSnapshots\",\n        \"ec2:DescribeSubnets\",\n        \"ec2:DescribeTags\",\n        \"ec2:DescribeVolumes\",\n        \"ec2:DetachVolume\",\n        \"ec2:GetPasswordData\",\n        \"ec2:ModifyImageAttribute\",\n        \"ec2:ModifyInstanceAttribute\",\n        \"ec2:ModifySnapshotAttribute\",\n        \"ec2:RegisterImage\",\n        \"ec2:RunInstances\",\n        \"ec2:StopInstances\",\n        \"ec2:TerminateInstances\"\n      ],\n      \"Resource\": \"*\"\n    }\n  ]\n}\n</code></pre>"},{"location":"#installing-packer-in-cloudshell","title":"\u2699\ufe0f Installing Packer in CloudShell","text":"<pre><code>sudo yum install -y yum-utils\nsudo yum-config-manager --add-repo https://rpm.releases.hashicorp.com/AmazonLinux/hashicorp.repo\nsudo yum -y install packer\npacker plugins install github.com/hashicorp/amazon\n\n</code></pre>"},{"location":"#cloning-the-github-repository","title":"\ud83d\uddc2\ufe0f Cloning the Github repository","text":"<pre><code>git clone https://github.com/aws-samples/amazon-eks-ami-rhel.git &amp;&amp; cd amazon-eks-ami-rhel\n\n</code></pre>"},{"location":"#building-the-ami","title":"\ud83d\udc77 Building the AMI","text":"<p>A Makefile is provided to build the Amazon EKS Worker AMI, but it is just a small wrapper around invoking Packer directly. You can initiate the build process by running the following command in the root of this repository:</p> <pre><code># Example for building an AMI with the latest Kubernetes version and the latest RHEL 8.9 AMI\nmake\n\n# Example for building an AMI with the latest Kubernetes version and the latest RHEL 8.9 AMI in us-gov-east-1 region\nmake k8s=1.29 ami_regions=us-gov-east-1 aws_region=us-gov-east-1\n\n# Example for building an AMI off of the latest RHEL 9.0.0 AMI in us-east-2 region\nmake k8s=1.29 source_ami_filter_name=RHEL-9.0.0_HVM-2023*-x86_64-* ami_regions=us-east-2 aws_region=us-east-2\n\n# Example for building a customized DISA STIG compliant AMI, owned by a specific AWS Account in AWS GovCloud us-gov-east-1 region, with binaries stored in a private S3 bucket, an IAM instance profile attached, a user data script to install the AWS Systems Manager agent, and using AWS Systems Manager Session Manager for Packer terminal access.\nmake k8s=1.29 source_ami_owners=123456789123 source_ami_filter_name=RHEL9_STIG_BASE*2023-04-14* ami_regions=us-gov-east-1 aws_region=us-gov-east-1 binary_bucket_name=my-eks-bucket binary_bucket_region=us-gov-east-1 iam_instance_profile=EC2Role pull_cni_from_github=false ssh_interface=session_manager user_data_file=/path/to/ssm_install.txt\n\n# Check default value and options in help doc\nmake help\n</code></pre> <p>The Makefile chooses a particular kubelet binary to use per Kubernetes version which you can view here.</p> <p>Note There is a network routing issue caused by the nm-cloud-setup service that comes preinstalled on RHEL machines. In the AWS Blog, we demonstrate how to disable this service and reboot the EC2 instances as recommended by Red Hat in the following KB article.</p> <p>Note The default instance type to build this AMI does not qualify for the AWS free tier. You are charged for any instances created when building this AMI.</p> <p>Note This has been tested on RHEL 8.6+ and RHEL 9+ images with 80+ DISA STIG SCAP scores.</p>"},{"location":"#security","title":"\ud83d\udd12 Security","text":"<p>For security issues or concerns, please do not open an issue or pull request on GitHub. Please report any suspected or confirmed security issues to AWS Security https://aws.amazon.com/security/vulnerability-reporting/</p>"},{"location":"#license-summary","title":"\u2696\ufe0f License Summary","text":"<p>This library is licensed under the MIT-0 License. See the LICENSE file.</p>"},{"location":"#legal-disclaimer","title":"\ud83d\udcdd Legal Disclaimer","text":"<p>The sample code; software libraries; command line tools; proofs of concept; templates; or other related technology (including any of the foregoing that are provided by our personnel) is provided to you as AWS Content under the AWS Customer Agreement, or the relevant written agreement between you and AWS (whichever applies). You should not use this AWS Content in your production accounts, or on production or other critical data. You are responsible for testing, securing, and optimizing the AWS Content, such as sample code, as appropriate for production grade use based on your specific quality control practices and standards. Deploying AWS Content may incur AWS charges for creating or using AWS chargeable resources, such as running Amazon EC2 instances or using Amazon S3 storage.</p>"},{"location":"CODE_OF_CONDUCT/","title":"Code of Conduct","text":""},{"location":"CODE_OF_CONDUCT/#code-of-conduct","title":"Code of Conduct","text":"<p>This project has adopted the Amazon Open Source Code of Conduct. For more information see the Code of Conduct FAQ or contact opensource-codeofconduct@amazon.com with any additional questions or comments.</p>"},{"location":"CONTRIBUTING/","title":"Contributing Guidelines","text":"<p>Thank you for your interest in contributing to our project. Whether it's a bug report, new feature, correction, or additional documentation, we greatly value feedback and contributions from our community.</p> <p>Please read through this document before submitting any issues or pull requests to ensure we have all the necessary information to effectively respond to your bug report or contribution.</p>"},{"location":"CONTRIBUTING/#reporting-bugsfeature-requests","title":"Reporting Bugs/Feature Requests","text":"<p>We welcome you to use the GitHub issue tracker to report bugs or suggest features.</p> <p>When filing an issue, please check existing open, or recently closed, issues to make sure somebody else hasn't already reported the issue. Please try to include as much information as you can. Details like these are incredibly useful:</p> <ul> <li>A reproducible test case or series of steps</li> <li>The version of our code being used</li> <li>Any modifications you've made relevant to the bug</li> <li>Anything unusual about your environment or deployment</li> </ul>"},{"location":"CONTRIBUTING/#contributing-via-pull-requests","title":"Contributing via Pull Requests","text":"<p>Contributions via pull requests are much appreciated. Before sending us a pull request, please ensure that:</p> <ol> <li>You are working against the latest source on the main branch.</li> <li>You check existing open, and recently merged, pull requests to make sure someone else hasn't addressed the problem already.</li> <li>You open an issue to discuss any significant work - we would hate for your time to be wasted.</li> </ol> <p>To send us a pull request, please:</p> <ol> <li>Fork the repository.</li> <li>Modify the source; please focus on the specific change you are contributing. If you also reformat all the code, it will be hard for us to focus on your change.</li> <li>Ensure your changes match our style guide (<code>make fmt</code>).</li> <li>Ensure local tests pass (<code>make test</code>).</li> <li>Commit to your fork using clear commit messages.</li> <li>Send us a pull request, answering any default questions in the pull request interface.</li> <li>Pay attention to any automated CI failures reported in the pull request, and stay involved in the conversation.</li> </ol> <p>GitHub provides additional document on forking a repository and creating a pull request.</p>"},{"location":"CONTRIBUTING/#testing-changes","title":"Testing Changes","text":"<p>When submitting PRs, we want to verify that there are no regressions in the AMI with the new changes. EKS runs various tests before publishing new Amazon EKS optimized Amazon Linux AMIs, which will ensure the highest level of confidence that there are no regressions in officially published AMIs. To maintain the health of this repo, we need to do some basic validation prior to merging PRs. Eventually, we hope to automate this process. Until then, here are the basic steps that we should take before merging PRs.</p> <p>Test #1: Verify that the unit tests pass</p> <p>Please add a test case for your changes, if possible. See the unit test README for more information. These tests will be run automatically for every pull request.</p> <pre><code>make test\n</code></pre> <p>Test #2: Verify that building AMIs still works</p> <p>If your change is relevant to a specific Kubernetes version, build all AMIs that apply. Otherwise, just choose the latest available Kubernetes version.</p> <pre><code># Configure AWS credentials\nmake 1.22\n</code></pre> <p>Test #3: Create a nodegroup with new AMI and confirm it joins a cluster</p> <p>Once the AMI is built, we need to verify that it can join a cluster. You can use <code>eksctl</code>, or your method of choice, to create a cluster and add nodes to it using the AMI you built. Below is an example config file.</p> <p><code>cluster.yaml</code></p> <pre><code>apiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\n\nmetadata:\n  name: basic-cluster\n  region: us-west-2\n  version: '1.22'\n\nnodeGroups:\n  - name: ng\n    instanceType: m5.large\n    ami: [INSERT_AMI_ID]\n    overrideBootstrapCommand: |\n      #!/bin/bash\n      /etc/eks/bootstrap.sh basic-cluster\n</code></pre> <p>Then run:</p> <pre><code>eksctl create cluster -f cluster.yaml\n</code></pre> <p><code>eksctl</code> will verify that the nodes join the cluster before completing.</p> <p>Test #4: Verify that the nodes are Kubernetes conformant</p> <p>You can use sonobuoy to run conformance tests on the cluster you've create in Test #2. You should only include nodes with the custom AMI built in Test #1. You must install <code>sonobuoy</code> locally before running.</p> <pre><code>sonobuoy run --wait\n</code></pre> <p>By default, <code>sonobuoy</code> will run <code>e2e</code> and <code>systemd-logs</code>. This step may take multiple hours to run.</p> <p>Test #5: [Optional] Test your specific PR changes</p> <p>If your PR has changes that require additional, custom validation, provide the appropriate steps to verify that the changes don't cause regressions and behave as expected. Document the steps taken in the CR.</p> <p>Clean Up</p> <p>Delete the cluster:</p> <pre><code>eksctl delete cluster -f cluster.yaml\n</code></pre>"},{"location":"CONTRIBUTING/#troubleshooting","title":"Troubleshooting","text":"<p>Tests fail with <code>realpath: command not found</code></p> <p>When running <code>make test</code>, you may see a message like below:</p> <pre><code>test/test-harness.sh: line 41: realpath: command not found\n/entrypoint.sh: line 13: /test.sh: No such file or directory\n</code></pre> <p>The issue is discussed in this StackExchange post.</p> <p>On OSX, running <code>brew install coreutils</code> resolves the issue.</p>"},{"location":"CONTRIBUTING/#finding-contributions-to-work-on","title":"Finding contributions to work on","text":"<p>Looking at the existing issues is a great way to find something to contribute on. As our projects, by default, use the default GitHub issue labels ((enhancement/bug/duplicate/help wanted/invalid/question/wontfix), looking at any 'help wanted' issues is a great place to start.</p>"},{"location":"CONTRIBUTING/#code-of-conduct","title":"Code of Conduct","text":"<p>This project has adopted the Amazon Open Source Code of Conduct. For more information see the Code of Conduct FAQ or contact opensource-codeofconduct@amazon.com with any additional questions or comments.</p>"},{"location":"CONTRIBUTING/#security-issue-notifications","title":"Security issue notifications","text":"<p>If you discover a potential security issue in this project we ask that you notify AWS/Amazon Security via our vulnerability reporting page. Please do not create a public github issue.</p>"},{"location":"CONTRIBUTING/#licensing","title":"Licensing","text":"<p>See the LICENSE file for our project's licensing. We will ask you to confirm the licensing of your contribution.</p> <p>We may ask you to sign a Contributor License Agreement (CLA) for larger changes.</p>"},{"location":"development/","title":"Development","text":""},{"location":"development/#writing-documentation","title":"Writing documentation","text":"<p>GitHub Pages serves a static site generated by <code>mkdoc</code>. A wrapper for <code>mkdoc</code> is provided by <code>hack/mkdoc.sh</code>.</p> <p>To serve the site locally, run:</p> <pre><code>hack/mkdocs.sh serve\n</code></pre>"},{"location":"development/#generating-max-pod-values","title":"Generating max pod values","text":"<p>By default, the maximum number of pods able to be scheduled on a node is based off of the number of ENIs available, which is determined by the instance type. Larger instances generally have more ENIs. The number of ENIs limits how many IPV4 addresses are available on an instance, and we need one IP address per pod. You can see this file for the code that calculates the max pods for more information.</p> <p>As an optimization, the default value for all known instance types are available in a resource file (<code>eni-max-pods.txt</code>) in the AMI. If an instance type is not found in this file, the <code>ec2:DescribeInstanceTypes</code> API is used to calculate the value at runtime.</p> <p>The resource file is generated once per day by a GitHub Action workflow.</p> <p>To generate the resource file:</p> <pre><code>git clone git@github.com:aws/amazon-vpc-cni-k8s.git\ncd amazon-vpc-cni-k8s/\nmake generate-limits\ncp misc/eni-max-pods.txt ../amazon-eks-ami-rhel/templates/shared/runtime/\n</code></pre>"},{"location":"nodegroups/","title":"Worker node group creation scripts","text":"<p>This directory contains sample scripts for creating EKS worker node groups after worker node AMI creation. These scripts were written to help you get started, not for production implementation!</p>"},{"location":"nodegroups/#announcements","title":"\ud83d\udd14 Announcements","text":""},{"location":"nodegroups/#worker-nodes-are-now-joined-to-eks-clusters-using-nodeadm","title":"Worker nodes are now joined to EKS clusters using nodeadm","text":"<p>The new method of joining EKS clusters using nodeadm is significantly different than the deprecated bootstrap.sh script method. For this reason, some sample scripts have been provided here to get you started.</p> <p>Note These changes require functionality that is not curently available using eksctl, so for now any scripts that reference eksctl are not working. A bug report has been submitted to address this issue.</p>"},{"location":"nodegroups/#usage","title":"\ud83d\udc77 Usage","text":"<p>Example command to launch a new worker node group with a custom configuration:</p> <pre><code>./create_nodegroup_cfn_zsh.sh rhel-eks ami-0b2e96e12344a54c0 rhel-eks-node-group us-gov-east-1 govcloud2024 t3.medium 3 3 3 https://5B3FFDCDC05F2D983E65079309123456.gr7.us-gov-east-1.eks.amazonaws.com 10.100.0.0/16 LS0tLS1CRUdLS0tLS0K \"subnet-0f034415c5b771234 subnet-0bdba07340be11234 subnet-05c651fa62a571234\" sg-038c07b2206e12345\n</code></pre> <p>This would create a node group with the following configuration:</p> <pre><code>Cluster: rhel-eks\nAMI ID: ami-0b2e96e12344a54c0\nNode group name: rhel-eks-node-group\nAWS Region: us-gov-east-1\nKeypair name: govcloud2024\nInstance type: t3.medium\nMin node group size: 3\nDesired node group size: 3\nMax node group size: 3\nEKS API endpoint: https://5B3FFDCDC05F2D983E65079309123456.gr7.us-gov-east-1.eks.amazonaws.com\nCIDR range: 10.100.0.0/16\nCertificate: LS0tLS1CRUdLS0tLS0K\nSubnet IDs: subnet-0f034415c5b771234 subnet-0bdba07340be11234 subnet-05c651fa62a571234\nSecurity group ID: sg-038c07b2206e12345\n</code></pre> <p>This command would generate a local CloudFormation template and execute the CloudFormation stack via the AWS CLI.</p>"},{"location":"nodegroups/#security","title":"\ud83d\udd12 Security","text":"<p>For security issues or concerns, please do not open an issue or pull request on GitHub. Please report any suspected or confirmed security issues to AWS Security https://aws.amazon.com/security/vulnerability-reporting/</p>"},{"location":"nodegroups/#license-summary","title":"\u2696\ufe0f License Summary","text":"<p>This library is licensed under the MIT-0 License. See the LICENSE file.</p>"},{"location":"nodegroups/#legal-disclaimer","title":"\ud83d\udcdd Legal Disclaimer","text":"<p>The sample code; software libraries; command line tools; proofs of concept; templates; or other related technology (including any of the foregoing that are provided by our personnel) is provided to you as AWS Content under the AWS Customer Agreement, or the relevant written agreement between you and AWS (whichever applies). You should not use this AWS Content in your production accounts, or on production or other critical data. You are responsible for testing, securing, and optimizing the AWS Content, such as sample code, as appropriate for production grade use based on your specific quality control practices and standards. Deploying AWS Content may incur AWS charges for creating or using AWS chargeable resources, such as running Amazon EC2 instances or using Amazon S3 storage.</p>"},{"location":"nodeadm/","title":"nodeadm","text":"<p>Initializes a node in an EKS cluster.</p>"},{"location":"nodeadm/#usage","title":"Usage","text":"<p>To initialize a node:</p> <pre><code>nodeadm init\n</code></pre>"},{"location":"nodeadm/#configuration","title":"Configuration","text":"<p><code>nodeadm</code> uses a YAML configuration schema that will look familiar to Kubernetes users.</p> <p>This is an example of the minimum required parameters:</p> <pre><code>---\napiVersion: node.eks.aws/v1alpha1\nkind: NodeConfig\nspec:\n  cluster:\n    name: my-cluster\n    apiServerEndpoint: https://example.com\n    certificateAuthority: Y2VydGlmaWNhdGVBdXRob3JpdHk=\n    cidr: 10.100.0.0/16\n</code></pre> <p>You'll typically provide this configuration in your EC2 instance's user data, either as-is or embedded within a MIME multi-part document:</p> <pre><code>MIME-Version: 1.0\nContent-Type: multipart/mixed; boundary=\"BOUNDARY\"\n\n--BOUNDARY\nContent-Type: application/node.eks.aws\n\n---\napiVersion: node.eks.aws/v1alpha1\nkind: NodeConfig\nspec: ...\n\n--BOUNDARY--\n</code></pre> <p>A different source for the configuration object can be specified with the <code>--config-source</code> flag.</p> <p>The API reference documentation contains the details of the configuration types.</p>"},{"location":"nodeadm/doc/api-concepts/","title":"API Concepts","text":""},{"location":"nodeadm/doc/api-concepts/#versioning","title":"Versioning","text":"<p>The API types for <code>nodeadm</code> (the <code>node.eks.aws</code> API group) are versioned in a similar manner to the Kubernetes API.</p> <p>There are three levels of stability and support:</p>"},{"location":"nodeadm/doc/api-concepts/#alpha","title":"Alpha","text":"<ul> <li>Example: <code>v1alpha2</code>.</li> <li>Support for an alpha API may be removed at any time.</li> <li>Subsequent alpha API versions may include incompatible changes, and migration instructions may not be provided.</li> </ul>"},{"location":"nodeadm/doc/api-concepts/#beta","title":"Beta","text":"<ul> <li>Example: <code>v3beta4</code>.</li> <li>Support for a beta API will remain for at least one release following its deprecation.</li> <li>Subsequent beta or stable API versions may include incompatible changes, and migration instructions will be provided.</li> </ul>"},{"location":"nodeadm/doc/api-concepts/#stable","title":"Stable","text":"<ul> <li>Example: <code>v5</code>.</li> <li>Support for a stable API will align with the support of a major version of Amazon Linux.</li> </ul>"},{"location":"nodeadm/doc/api/","title":"API Reference","text":""},{"location":"nodeadm/doc/api/#packages","title":"Packages","text":"<ul> <li>node.eks.aws/v1alpha1</li> </ul>"},{"location":"nodeadm/doc/api/#nodeeksawsv1alpha1","title":"node.eks.aws/v1alpha1","text":""},{"location":"nodeadm/doc/api/#resource-types","title":"Resource Types","text":"<ul> <li>NodeConfig</li> </ul>"},{"location":"nodeadm/doc/api/#clusterdetails","title":"ClusterDetails","text":"<p>ClusterDetails contains the coordinates of your EKS cluster. These details can be found using the DescribeCluster API.</p> <p>Appears in: - NodeConfigSpec</p> Field Description <code>name</code> string Name is the name of your EKS cluster <code>apiServerEndpoint</code> string APIServerEndpoint is the URL of your EKS cluster's kube-apiserver. <code>certificateAuthority</code> byte array CertificateAuthority is a base64-encoded string of your cluster's certificate authority chain. <code>cidr</code> string CIDR is your cluster's service CIDR block. This value is used to infer your cluster's DNS address. <code>enableOutpost</code> boolean EnableOutpost determines how your node is configured when running on an AWS Outpost. <code>id</code> string ID is an identifier for your cluster; this is only used when your node is running on an AWS Outpost."},{"location":"nodeadm/doc/api/#containerdoptions","title":"ContainerdOptions","text":"<p>ContainerdOptions are additional parameters passed to <code>containerd</code>.</p> <p>Appears in: - NodeConfigSpec</p> Field Description <code>config</code> string Config is an inline <code>containerd</code> configuration TOML that will be merged with the defaults. <code>baseRuntimeSpec</code> object (keys:string, values:RawExtension) BaseRuntimeSpec is the OCI runtime specification upon which all containers will be based. The provided spec will be merged with the default spec; so that a partial spec may be provided. For more information, see: https://github.com/opencontainers/runtime-spec"},{"location":"nodeadm/doc/api/#feature","title":"Feature","text":"<p>Underlying type: string</p> <p>Feature specifies which feature gate should be toggled</p> <p>Appears in: - NodeConfigSpec</p> <p>.Validation: - Enum: [InstanceIdNodeName]</p>"},{"location":"nodeadm/doc/api/#instanceoptions","title":"InstanceOptions","text":"<p>InstanceOptions determines how the node's operating system and devices are configured.</p> <p>Appears in: - NodeConfigSpec</p> Field Description <code>localStorage</code> LocalStorageOptions"},{"location":"nodeadm/doc/api/#kubeletoptions","title":"KubeletOptions","text":"<p>KubeletOptions are additional parameters passed to <code>kubelet</code>.</p> <p>Appears in: - NodeConfigSpec</p> Field Description <code>config</code> object (keys:string, values:RawExtension) Config is a <code>KubeletConfiguration</code> that will be merged with the defaults. <code>flags</code> string array Flags are command-line <code>kubelet</code> arguments. that will be appended to the defaults."},{"location":"nodeadm/doc/api/#localstorageoptions","title":"LocalStorageOptions","text":"<p>LocalStorageOptions control how EC2 instance stores are used when available.</p> <p>Appears in: - InstanceOptions</p> Field Description <code>strategy</code> LocalStorageStrategy"},{"location":"nodeadm/doc/api/#localstoragestrategy","title":"LocalStorageStrategy","text":"<p>Underlying type: string</p> <p>LocalStorageStrategy specifies how to handle an instance's local storage devices.</p> <p>Appears in: - LocalStorageOptions</p> <p>.Validation: - Enum: [RAID0 Mount]</p>"},{"location":"nodeadm/doc/api/#nodeconfig","title":"NodeConfig","text":"<p>NodeConfig is the primary configuration object for <code>nodeadm</code>.</p> Field Description <code>apiVersion</code> string <code>node.eks.aws/v1alpha1</code> <code>kind</code> string <code>NodeConfig</code> <code>kind</code> string Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds <code>apiVersion</code> string APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources <code>metadata</code> ObjectMeta Refer to Kubernetes API documentation for fields of <code>metadata</code>. <code>spec</code> NodeConfigSpec"},{"location":"nodeadm/doc/api/#nodeconfigspec","title":"NodeConfigSpec","text":"<p>Appears in: - NodeConfig</p> Field Description <code>cluster</code> ClusterDetails <code>containerd</code> ContainerdOptions <code>instance</code> InstanceOptions <code>kubelet</code> KubeletOptions <code>featureGates</code> object (keys:Feature, values:boolean) FeatureGates holds key-value pairs to enable or disable application features."},{"location":"nodeadm/doc/examples/","title":"Examples","text":""},{"location":"nodeadm/doc/examples/#merging-multiple-configuration-objects","title":"Merging multiple configuration objects","text":"<p>When using the IMDS configuration source (<code>--config-source=imds://user-data</code>), <code>nodeadm</code> will merge any configuration objects it discovers before configuring your node.</p> <p>With the following user data:</p> <pre><code>MIME-Version: 1.0\nContent-Type: multipart/mixed; boundary=\"BOUNDARY\"\n\n--BOUNDARY\nContent-Type: application/node.eks.aws\n\n---\napiVersion: node.eks.aws/v1alpha1\nkind: NodeConfig\nspec:\n  cluster:\n    name: my-cluster\n    apiServerEndpoint: https://example.com\n    certificateAuthority: Y2VydGlmaWNhdGVBdXRob3JpdHk=\n    cidr: 10.100.0.0/16\n\n--BOUNDARY--\nContent-Type: application/node.eks.aws\n\n---\napiVersion: node.eks.aws/v1alpha1\nkind: NodeConfig\nspec:\n  kubelet:\n    config:\n      shutdownGracePeriod: 30s\n      featureGates:\n        DisableKubeletCloudCredentialProviders: true\n\n--BOUNDARY--\n</code></pre> <p>The configuration <code>nodeadm</code> will use is:</p> <pre><code>---\napiVersion: node.eks.aws/v1alpha1\nkind: NodeConfig\nspec:\n  cluster:\n    name: my-cluster\n    apiServerEndpoint: https://example.com\n    certificateAuthority: Y2VydGlmaWNhdGVBdXRob3JpdHk=\n    cidr: 10.100.0.0/16\n  kubelet:\n    config:\n      shutdownGracePeriod: 30s\n      featureGates:\n        DisableKubeletCloudCredentialProviders: true\n</code></pre> <p>The configuration objects will be merged in the order they appear in the MIME multi-part document, meaning the value in the lattermost configuration object will take precedence.</p>"},{"location":"nodeadm/doc/examples/#using-instance-id-as-node-name-experimental","title":"Using instance ID as node name (experimental)","text":"<p>When the <code>InstanceIdNodeName</code> feature gate is enabled, <code>nodeadm</code> will use the EC2 instance's ID (e.g. <code>i-abcdefg1234</code>) as the name of the <code>Node</code> object created by <code>kubelet</code>, instead of the EC2 instance's private DNS Name (e.g. <code>ip-192-168-1-1.ec2.internal</code>). There are several benefits of doing this: 1. Your <code>Node</code> names are more meaningful in, for example, the output of <code>kubectl get nodes</code>. 2. The <code>Node</code> name, which is in the critical path of <code>kubelet</code> authentication, is non-volatile. While the private DNS name of an instance may change, its ID cannot. 3. The <code>ec2:DescribeInstances</code> permission can be removed from your node role's IAM policy; this is no longer necessary.</p>"},{"location":"nodeadm/doc/examples/#to-enable-this-feature-you-will-need-to","title":"To enable this feature, you will need to:","text":"<ol> <li>Create a new worker node IAM role<ul> <li>\u26a0\ufe0f Note: you should create a new role when migrating an existing cluster to avoid authentication failures on existing nodes.</li> </ul> </li> <li>Update the <code>aws-auth</code> ConfigMap with above created role. For example:</li> </ol> <pre><code>- groups:\n  - system:bootstrappers\n  - system:nodes\n  rolearn: $ROLE_CREATED_ABOVE\n  username: system:node:{{SessionName}}\n</code></pre> <ol> <li>Enable the feature gate in your user data:</li> </ol> <pre><code>---\napiVersion: node.eks.aws/v1alpha1\nkind: NodeConfig\nspec:\n  featureGates:\n    InstanceIdNodeName: true\n</code></pre>"},{"location":"nodeadm/doc/examples/#configuring-containerd","title":"Configuring <code>containerd</code>","text":"<p>Additional <code>containerd</code> configuration can be supplied in your <code>NodeConfig</code>. The values in your inline TOML document will overwrite any default value set by <code>nodeadm</code>.</p> <p>The following configuration object:</p> <pre><code>---\napiVersion: node.eks.aws/v1alpha1\nkind: NodeConfig\nspec:\n  cluster: ...\n  containerd:\n    config: |\n      [plugins.\"io.containerd.grpc.v1.cri\".containerd]\n      discard_unpacked_layers = false\n</code></pre> <p>Can be used to disable deletion of unpacked image layers in the <code>containerd</code> content store.</p>"},{"location":"nodeadm/doc/examples/#modifying-container-rlimits","title":"Modifying container RLIMITs","text":"<p>If your workload requires different RLIMITs than the defaults, you can use the <code>baseRuntimeSpec</code> option of <code>containerd</code> to override them:</p> <pre><code>---\napiVersion: node.eks.aws/v1alpha1\nkind: NodeConfig\nspec:\n  cluster: ...\n  containerd:\n    baseRuntimeSpec:\n      process:\n        rlimits:\n          - type: RLIMIT_NOFILE\n            soft: 1024\n            hard: 1024\n</code></pre>"},{"location":"usage/overview/","title":"AMI templates","text":""},{"location":"usage/overview/#variables","title":"Variables","text":"<p>Templates are defined for each OS distribution, each with variables whose defaults depend on specified Kubernetes version.</p> <p>Users have the following options for specifying their own values:</p> <ol> <li>Provide a variable file with the <code>PACKER_VARIABLE_FILE</code> argument to <code>make</code>. Values in this file will override values in the default variable file. Your variable file does not need to include all possible variables, as it will be merged with the default variable file.</li> <li>Pass a key-value pair for any template variable to <code>make</code>. These values will override any values that were specified with the first method.</li> </ol> <p>Note Some variables (such as <code>arch</code> and <code>kubernetes_version</code>) do not have a sensible, static default, and are satisfied by the Makefile. Such variables do not appear in the default variable file, and must be overridden (if necessary) by a method described above.</p>"},{"location":"usage/overview/#kubernetes-binaries","title":"Kubernetes binaries","text":"<p>When building the AMI, binaries such as <code>kubelet</code>, <code>aws-iam-authenticator</code>, and <code>ecr-credential-provider</code> are installed.</p>"},{"location":"usage/overview/#using-the-latest","title":"Using the latest","text":"<p>It is recommended that the latest available binaries are used, as they may contain important fixes for bugs or security issues. The latest binaries can be discovered with the following script:</p> <pre><code>hack/latest-binaries.sh $KUBERNETES_MINOR_VERSION\n</code></pre> <p>This script will return the values for the binary-related AMI template variables, for example:</p> <pre><code>&gt; hack/latest-binaries.sh 1.28\n\nkubernetes_version=1.28.1 kubernetes_build_date=2023-10-01\n</code></pre>"},{"location":"usage/overview/#using-a-specific-version","title":"Using a specific version","text":"<p>Use the following commands to obtain values for the binary-related AMI template variables:</p> <pre><code># List Kubernetes versions\naws s3 ls s3://amazon-eks\n\n# List build dates\naws s3 ls s3://amazon-eks/1.23.9/\n\n# List platforms\naws s3 ls s3://amazon-eks/1.23.9/2022-07-27/bin/\n\n# List architectures\naws s3 ls s3://amazon-eks/1.23.9/2022-07-27/bin/linux/\n\n# List binaries\naws s3 ls s3://amazon-eks/1.23.9/2022-07-27/bin/linux/x86_64/\n</code></pre> <p>To build using the example binaries above:</p> <pre><code>make k8s \\\n  kubernetes_version=1.23.9 \\\n  kubernetes_build_date=2022-07-27 \\\n  arch=x86_64\n</code></pre>"},{"location":"usage/overview/#providing-your-own","title":"Providing your own","text":"<p>By default, binaries are downloaded from the public S3 bucket <code>amazon-eks</code> in <code>us-west-2</code>. You can instead provide your own version of Kubernetes binaries.</p> <p>To use your own binaries:</p> <ol> <li>Copy all of the necessary binaries to your own S3 bucket using the AWS CLI. For example:</li> </ol> <pre><code> aws s3 cp kubelet s3://$BUCKET/$KUBERNETES_VERSION/$KUBERNETES_BUILD_DATE/bin/linux/$ARCH/kubelet\n</code></pre> <p>Important: You must provide all the binaries present in the default <code>amazon-eks</code> bucket for a specific <code>KUBERNETES_VERSION</code>, <code>KUBERNETES_BUILD_DATE</code>, and <code>ARCH</code> combination. These binaries must be accessible using the credentials on the Packer builder EC2 instance.</p> <ol> <li>Run the following command to start the build process to use your own Kubernetes binaries:</li> </ol> <pre><code>make k8s \\\n  binary_bucket_name=my-custom-bucket \\\n  binary_bucket_region=eu-west-1 \\\n  kubernetes_version=1.14.9 \\\n  kubernetes_build_date=2020-01-22\n</code></pre> <p>Note: Confirm that the binary_bucket_name, binary_bucket_region, kubernetes_version, and kubernetes_build_date parameters match the path to your binaries in Amazon S3.</p>"},{"location":"usage/overview/#iam-permissions","title":"IAM Permissions","text":"<p>To build the EKS Optimized AMI, you will need the following permissions:</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"ec2:AttachVolume\",\n                \"ec2:AuthorizeSecurityGroupIngress\",\n                \"ec2:CopyImage\",\n                \"ec2:CreateImage\",\n                \"ec2:CreateKeypair\",\n                \"ec2:CreateSecurityGroup\",\n                \"ec2:CreateSnapshot\",\n                \"ec2:CreateTags\",\n                \"ec2:CreateVolume\",\n                \"ec2:DeleteKeyPair\",\n                \"ec2:DeleteSecurityGroup\",\n                \"ec2:DeleteSnapshot\",\n                \"ec2:DeleteVolume\",\n                \"ec2:DeregisterImage\",\n                \"ec2:DescribeImageAttribute\",\n                \"ec2:DescribeImages\",\n                \"ec2:DescribeInstances\",\n                \"ec2:DescribeInstanceStatus\",\n                \"ec2:DescribeRegions\",\n                \"ec2:DescribeSecurityGroups\",\n                \"ec2:DescribeSnapshots\",\n                \"ec2:DescribeSubnets\",\n                \"ec2:DescribeTags\",\n                \"ec2:DescribeVolumes\",\n                \"ec2:DetachVolume\",\n                \"ec2:GetPasswordData\",\n                \"ec2:ModifyImageAttribute\",\n                \"ec2:ModifyInstanceAttribute\",\n                \"ec2:ModifySnapshotAttribute\",\n                \"ec2:RegisterImage\",\n                \"ec2:RunInstances\",\n                \"ec2:StopInstances\",\n                \"ec2:TerminateInstances\",\n                \"eks:DescribeAddonVersions\",\n                \"ecr:GetAuthorizationToken\"\n            ],\n            \"Resource\": \"*\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"ecr:BatchGetImage\",\n                \"ecr:BatchCheckLayerAvailability\",\n                \"ecr:GetDownloadUrlForLayer\"\n            ],\n            \"Resource\": \"arn:aws:ecr:us-west-2:602401143452:repository/*\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:GetObject\",\n                \"s3:ListBucket\"\n            ],\n            \"Resource\": [\n                \"arn:aws:s3:::amazon-eks/*\",\n                \"arn:aws:s3:::amazon-eks\"\n            ]\n        }\n    ]\n}\n</code></pre> <p>You will need to use the region you are building the AMI in to specify the ECR repository resource in the second IAM statement. You may also need to change the account if you are building the AMI in a different partition or special region. You can see a mapping of regions to account ID here. If you're using a custom s3 bucket to vend different K8s binaries, you will need to change the resource in the third IAM statement above to reference your custom bucket. For more information about the permissions required by Packer with different configurations, see the docs.</p>"},{"location":"usage/overview/#image-credential-provider-plugins","title":"Image credential provider plugins","text":"<p>Prior to Kubernetes 1.27, the <code>kubelet</code> could obtain credentials for ECR out of the box. This legacy credential process has been removed in Kubernetes 1.27, and ECR credentials should now be obtained via a plugin, the <code>ecr-credential-provider</code>. This plugin is installed in the AMI at <code>/etc/eks/image-credential-provider/ecr-credential-provider</code>. More information about this plugin is available in the <code>cloud-provider-aws</code> documentation.</p> <p>Additional image credential provider plugins may be appended to <code>/etc/eks/image-credential-provider/config.json</code>. In Kubernetes versions 1.26 and below, all plugins in this file must support <code>credentialprovider.kubelet.k8s.io/v1alpha1</code>. In Kubernetes versions 1.27 and above, they must support <code>credentialprovider.kubelet.k8s.io/v1</code>.</p> <p>For more information about image credential provider plugins, refer to the Kubernetes documentation.</p>"},{"location":"usage/rhel/","title":"Red Hat Enterprise Linux","text":""},{"location":"usage/rhel/#template-variables","title":"Template variables","text":"Variable Description <code>ami_component_description</code> <code>ami_description</code> <code>ami_name</code> <code>ami_regions</code> <code>ami_users</code> <code>arch</code> <code>associate_public_ip_address</code> <code>aws_access_key_id</code> <code>aws_region</code> <code>aws_secret_access_key</code> <code>aws_session_token</code> <code>binary_bucket_name</code> <code>binary_bucket_region</code> <code>containerd_version</code> <code>creator</code> <code>enable_fips</code> Install openssl and enable fips related kernel parameters <code>encrypted</code> <code>iam_instance_profile</code> The name of an IAM instance profile to launch the EC2 instance with. <code>enable_efa</code> Valid options are <code>true</code> or <code>false</code>. Wheather or not to install the software needed to use AWS Elastic Fabric Adapter (EFA) network interfaces. <code>instance_type</code> <code>kms_key_id</code> <code>kubernetes_build_date</code> <code>kubernetes_version</code> <code>launch_block_device_mappings_volume_size</code> <code>nerdctl_url</code> <code>remote_folder</code> Directory path for shell provisioner scripts on the builder instance <code>runc_version</code> <code>security_group_id</code> <code>source_ami_filter_name</code> <code>source_ami_id</code> <code>source_ami_owners</code> <code>ssh_interface</code> If using <code>session_manager</code>, you need to ensure your AMI has the SSM agent installed as the default RHEL AMIs do not have the SSM agent installed. This can be achieved through a user_data_file script. <code>ssh_username</code> <code>ssm_agent_version</code> Version of the SSM agent to install from the S3 bucket provided by the SSM agent project, such as <code>latest</code>. If empty, the latest version of the SSM agent available will be installed. <code>subnet_id</code> <code>temporary_key_pair_type</code> <code>temporary_security_group_source_cidrs</code> <code>user_data_file</code> Path to a file that will be used for the user data when launching the instance. <code>volume_type</code> <code>vpc_id</code> <code>working_dir</code> Directory path for ephemeral resources on the builder instance"}]}